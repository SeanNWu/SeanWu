<!DOCTYPE html>
<html>
  <head>
    <title>Sean Wu - Undergraduate Researcher at Pepperdine</title>
    <style>
      body {
        margin-left: 200px;
        margin-right: 200px;
      }

    </style>
  </head>
  <body>
    <h1 style="margin-top:20px; margin-bottom:20px;">Sean Wu</h1>
    <img src="seanwu.jpg" width="200" height="250" class="profile">
    <p> I am passionate about conducting research in the fields of deep learning and computer vision, particularly in their application to medicine. Through my work, I strive to contribute to the development of innovative solutions that can improve healthcare outcomes diagnosis. I invite you to explore my portfolio and learn more about my projects and achievements.</p>
   
    <br>
    

    <h2>Research Projects</h2>
    
    <h3>Deep Learning in Ophthalmology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="4.png" width="250" height="150"></td>
        <td>Text<!--write stuff here--></td>
      </tr>
      <tr>
        <td><img src="2.png" width="250" height="150"></td>
        <td>I lead a study that proposes a framework that uses auxiliary tasks to improve the accuracy of predicting glaucoma progression using a convolutional neural network. The framework utilizes patient age, mean deviation, and optical coherence tomography data to train the model. The study compares baseline models with no auxiliary outputs to the ones built using auxiliary tasks and observes a 6.5% increase in AUC-ROC in the final auxiliary-domain model. The proposed framework demonstrates the usefulness of auxiliary tasks when training ophthalmology models and leveraging important patient data that may not be readily available in routine clinical care.</td>
      </tr>
      <tr>
        <td><img src="3.png" width="250" height="150"></td>
        <td>I was involved in a method to predict central 10Â° global and local visual field (VF) measurements using macular optical coherence tomography (OCT) volume scans with deep learning (DL). Our study included 1121 OCT volume scans and 10-2 VFs from 289 eyes (257 patients). We used macular scans to estimate 10-2 VF mean deviation (MD), threshold sensitivity (TS), and total deviation (TD) at 68 locations, and a 3D Convolutional Neural Network based on 3D DenseNet121 architecture was used for prediction. We compared DL predictions to those from broken-stick models (BM) and carried out 10-fold stratified cross-validation to optimize generalizability. The performance of DL and broken-stick models was compared based on correlations between ground truth and predicted VF measures and mean absolute error (MAE: ground truth-minus-predicted values). We found that macular OCT volume scans can be used to predict global central VF parameters with clinically relevant accuracy.</td>
      </tr>
    </table>
    
    <h3>Artificial Intelligence in Ecology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="6.png" width="250" height="150"></td>
        <td>Text<!--write stuff here--></td>
      </tr>
      <tr>
        <td><img src="9.png" width="250" height="150"></td>
        <td>Text<!--write stuff here--></td>
      </tr>
    </table>
    
    <h3>Natural Language Processing</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="6.png" width="250" height="150"></td>
        <td>Text<!--write stuff here--></td>
      </tr>
      <tr>
        <td><img src="7.png" width="250" height="150"></td>
        <td>Text<!--write stuff here--></td>
      </tr>
    </table>
    
    <h3>Interventional Neurology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="1.png" width="250" height="150"></td>
        <td>This is an ongoing paper that presents an innovative approach to perform a 2D to 3D reconstruction of Biplane DSA. I am proposing a Deep Neural Network (DNN) that can learn the mapping function between a pair of DSA images and a 3D surface mesh. This study uses various CNN encoders and output dimensions to explore the optimal design of the model. The outputted dimensions include two n x 3 dimensional vectors and a multi-output CNN with three independent fully connected layers. The performance of the model was evaluated using Chamfer Distance, and the results indicate that the proposed DNN can accurately predict the faces and vertices of the angiogram. The study also highlights the benefits of bypassing the surface reconstruction step by parameterizing the ground truth into two arrays of vertices and faces that can be directly utilized by radiologists.</td>
      </tr>
    </table>
    
    <h3>Others</h3>
 <table cellspacing="10">
      <tr>
        <td><img src="8.png" width="250" height="150"></td>
        <td>I co-lead research on the use of deep neural networks and transformer networks in medical imaging, specifically in determining salient regions. To address this challenge, I explored the application of dictionary learning theory as a potential solution. My study involved analyzing the Big Healthy Brains (BHB) dataset, which contains T1 MRI brain images from 10 healthy sites. Through comparisons with Grad-CAM and other visualizations, I found that my approach was more quantitative and precise in identifying subtle salient features that are likely utilized by ResNet and Vision Transformers models. Overall, my work demonstrated the potential for using dictionary learning theory in medical imaging to enhance the accuracy and effectiveness of deep learning models.</td>
      </tr>
    
    </table>
    
